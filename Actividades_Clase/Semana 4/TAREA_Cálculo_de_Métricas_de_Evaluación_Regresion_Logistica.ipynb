{"cells":[{"cell_type":"markdown","metadata":{"id":"sP2xWPFg2CjG"},"source":["# Cálculo de Métricas de Evaluación para Clasificación:"]},{"cell_type":"markdown","source":["## Ejemplo/Ejercicio:"],"metadata":{"id":"Tu6ym-IDfBsY"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZiSQWW9a2CjJ","outputId":"7cc9734c-ef8d-47bb-86dc-d7c3d7201d96","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718667524717,"user_tz":300,"elapsed":6989,"user":{"displayName":"Carlos Diaz","userId":"09094496570476557141"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["X_train:  (1437, 64)\n","X_test:  (360, 64)\n","y_train:  (1437,)\n","y_test:  (360,)\n","X_train:  [[ 0.  0.  3. ... 13.  4.  0.]\n"," [ 0.  0.  9. ...  3.  0.  0.]\n"," [ 0.  0.  0. ...  6.  0.  0.]\n"," ...\n"," [ 0.  0.  9. ... 16.  2.  0.]\n"," [ 0.  0.  1. ...  0.  0.  0.]\n"," [ 0.  0.  1. ...  1.  0.  0.]]\n","X_test:  [[ 0.  0.  0. ... 14.  5.  0.]\n"," [ 0.  0. 11. ...  1.  0.  0.]\n"," [ 0.  0.  8. ...  8.  0.  0.]\n"," ...\n"," [ 0.  0.  7. ... 10.  0.  0.]\n"," [ 0.  0.  7. ... 16.  4.  0.]\n"," [ 0.  0. 14. ...  5.  0.  0.]]\n","y_train:  [6 0 0 ... 2 7 1]\n","y_test:  [6 9 3 7 2 1 5 2 5 2 1 9 4 0 4 2 3 7 8 8 4 3 9 7 5 6 3 5 6 3 4 9 1 4 4 6 9\n"," 4 7 6 6 9 1 3 6 1 3 0 6 5 5 1 9 5 6 0 9 0 0 1 0 4 5 2 4 5 7 0 7 5 9 5 5 4\n"," 7 0 4 5 5 9 9 0 2 3 8 0 6 4 4 9 1 2 8 3 5 2 9 0 4 4 4 3 5 3 1 3 5 9 4 2 7\n"," 7 4 4 1 9 2 7 8 7 2 6 9 4 0 7 2 7 5 8 7 5 7 7 0 6 6 4 2 8 0 9 4 6 9 9 6 9\n"," 0 3 5 6 6 0 6 4 3 9 3 9 7 2 9 0 4 5 3 6 5 9 9 8 4 2 1 3 7 7 2 2 3 9 8 0 3\n"," 2 2 5 6 9 9 4 1 5 4 2 3 6 4 8 5 9 5 7 8 9 4 8 1 5 4 4 9 6 1 8 6 0 4 5 2 7\n"," 4 6 4 5 6 0 3 2 3 6 7 1 5 1 4 7 6 8 8 5 5 1 6 2 8 8 9 9 7 6 2 2 2 3 4 8 8\n"," 3 6 0 9 7 7 0 1 0 4 5 1 5 3 6 0 4 1 0 0 3 6 5 9 7 3 5 5 9 9 8 5 3 3 2 0 5\n"," 8 3 4 0 2 4 6 4 3 4 5 0 5 2 1 3 1 4 1 1 7 0 1 5 2 1 2 8 7 0 6 4 8 8 5 1 8\n"," 4 5 8 7 9 8 5 0 6 2 0 7 9 8 9 5 2 7 7 1 8 7 4 3 8 3 5]\n","Exactitud: 0.9722222222222222\n","Precisión: 0.9725599634194969\n","Recuperación o sensibilidad (recall): 0.9722222222222222\n","Puntuación o medida F1 (F1-score): 0.9722809227439473\n"]}],"source":["from sklearn.datasets import load_digits\n","from keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc, classification_report, confusion_matrix, ConfusionMatrixDisplay\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import label_binarize\n","\n","# Cargar el conjunto de datos\n","digits = load_digits()\n","X, y = digits.data, digits.target\n","\n","# Dividir el conjunto de datos en entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print(\"X_train: \", X_train.shape)\n","print(\"X_test: \", X_test.shape)\n","print(\"y_train: \", y_train.shape)\n","print(\"y_test: \", y_test.shape)\n","\n","print(\"X_train: \", X_train)\n","print(\"X_test: \", X_test)\n","print(\"y_train: \", y_train)\n","print(\"y_test: \", y_test)\n","\n","# Entrenar el modelo usando regresion logistica\n","model = LogisticRegression(max_iter=10000)\n","model.fit(X_train, y_train)\n","model.score(X_train, y_train)\n","\n","\n","\n","# Realizar predicciones\n","y_pred = model.predict(X_test)\n","\n","# Calcular métricas de evaluación\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","\n","# Mostrar las métricas\n","print(\"Exactitud:\", accuracy)\n","print(\"Precisión:\", precision)\n","print(\"Recuperación o sensibilidad (recall):\", recall)\n","print(\"Puntuación o medida F1 (F1-score):\", f1)\n","\n","\"\"\"\n","# One-hot encode y_test and y_score\n","y_test_onehot = to_categorical(y_test)\n","y_score_onehot = to_categorical(y_pred)\n","# Replace \"y_true\" and \"y_score\" with your actual values\n","\n","y_true = y_test_onehot.ravel()  # Replace with your actual true labels\n","y_score_onehot = model.predict_proba(X_test)[:, 1]  # Replace with your actual predicted probabilities\n","\n","fpr, tpr, thresholds = roc_curve_multiclass(y_test_onehot, y_score_onehot)\n","roc_auc = auc(fpr, tpr)\n","\n","# Calculate FPR at a specific threshold (e.g., 0.5)\n","fpr_at_threshold = fpr[np.argmax(tpr > 0.5)]\n","\n","# Calculate TPR at a specific threshold (e.g., 0.5)\n","tpr_at_threshold = tpr[np.argmax(tpr > 0.5)]\n","\"\"\"\n","# Binarize the output\n","y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n","n_classes = y_test_bin.shape[1]\n","\n","y_score = model.predict_proba(X_test)\n","\n","# Compute ROC curve and ROC area for each class\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","for i in range(n_classes):\n","    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Compute micro-average ROC curve and ROC area\n","fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\n","roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","#Now you can use fpr, tpr, and roc_auc to plot or analyze the ROC curves for each class.\n"]},{"cell_type":"markdown","source":["### TAREA en clase/casa (reference - pumpkins homework):\n","\n","Usando alguna herramienta de IA, consultar (dos versiones: para codificar \"a mano\" y con código python existente en bobliotecas):\n","\n","1. Qué es y cómo se obtiene la matriz de confusíón:\n","\n","The confusion matrix is a table that summarizes the performance of a classification model. It shows the number of correct and incorrect predictions for each class.\n","To obtain the confusion matrix, you first need to make predictions on a set of data. This can be done using the predict method of your trained model.\n","Once you have your predictions, you can use the confusion_matrix function from the sklearn.metrics module to calculate the confusion matrix.\n","2. Analizar el resultado de la matriz de confusión del anterior ejemplo/ejercicio.\n","\n","En la tabla de la matriz de confusión se resume el desempeño de un modelo de clasificación motrando el número de predicciones correctas e incorrectas para cada clase.  lo que sirve para analizar los resultados de una matriz de confusión se deben observar las siguientes métricas:\n","\n","Accuracy: Es el porcentaje general de predicciones correctas. Se calcula dividiendo el número de predicciones correctas por el número total de predicciones.\n","Precisión: Que es el porcentaje de predicciones positivas que realmente son correctas. Se calcula dividiendo el número de verdaderos positivos por el número total de predicciones positivas.\n","Recall: Es el porcentaje de positivos reales que se predicen correctamente. Se calcula dividiendo el número de verdaderos positivos por el número total de positivos reales.\n","F1 score: Es la media armónica de precisión y recuperación. Se calcula tomando el promedio ponderado de precisión y recuperación, donde el peso es 2.\n","\n","3. Obtener las formulas de TP, TN, FP, FN, precision, recall, F1-score, support.\n","\n","# True Positives (TP):\n","tp = confusion_matrix[0, 0]\n","# True Negatives (TN):\n","tn = confusion_matrix[1, 1]\n","# False Positives (FP):\n","fp = confusion_matrix[0, 1]\n","# False Negatives (FN):\n","fn = confusion_matrix[1, 0]\n","# Precision:\n","precision = tp / (tp + fp)\n","# Recall:\n","recall = tp / (tp + fn)\n","# F1 score:\n","f1_score = 2 * (precision * recall) / (precision + recall)\n","# Support:\n","support = tp + tn + fp + fn\n","\n","4. Apartir de la matriz de confusión, interpretar los resultados del item 3.\n","5. Con base en lo anterior, calcular, graficar e interpretar: FPR, TPR, ROC, AUC.\n"],"metadata":{"id":"LS0S43ilkFwr"}},{"cell_type":"code","source":["# Calcular Confusión Matriz\n","cm = confusion_matrix(y_test, y_pred)\n","\n","# True Positives (TP):\n","tp = cm[0, 0]\n","# True Negatives (TN):\n","tn = cm[1, 1]\n","# False Positives (FP):\n","fp = cm[0, 1]\n","# False Negatives (FN):\n","fn = cm[1, 0]\n","# Precision:\n","precision = tp / (tp + fp)\n","# Recall:\n","recall = tp / (tp + fn)\n","# F1 score:\n","f1_score = 2 * (precision * recall) / (precision + recall)\n","# Support:\n","support = tp + tn + fp + fn\n","\n","# Mostrar las los datos de la matriz de confusión\n","\n","print(\"Matriz de confusión:\")\n","print(cm)\n","print(\"TP:\", tp)\n","print(\"TN:\", tn)\n","print(\"FP:\", fp)\n","print(\"FN:\", fn)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1 score:\", f1_score)\n","print(\"Support:\", support)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nNCQPuNnou7V","executionInfo":{"status":"ok","timestamp":1718394922262,"user_tz":300,"elapsed":211,"user":{"displayName":"Carlos Arturo Diaz Bonilla","userId":"01801615585783068100"}},"outputId":"9f06ea86-5f23-4929-9919-f9710ec8d2be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Matriz de confusión:\n","[[33  0  0  0  0  0  0  0  0  0]\n"," [ 0 28  0  0  0  0  0  0  0  0]\n"," [ 0  0 33  0  0  0  0  0  0  0]\n"," [ 0  0  0 33  0  1  0  0  0  0]\n"," [ 0  1  0  0 45  0  0  0  0  0]\n"," [ 0  0  1  0  0 44  1  0  0  1]\n"," [ 0  0  0  0  0  1 34  0  0  0]\n"," [ 0  0  0  0  0  1  0 33  0  0]\n"," [ 0  0  0  0  0  1  0  0 29  0]\n"," [ 0  0  0  1  0  0  0  0  1 38]]\n","TP: 33\n","TN: 28\n","FP: 0\n","FN: 0\n","Precision: 1.0\n","Recall: 1.0\n","F1 score: 1.0\n","Support: 61\n"]}]},{"cell_type":"code","source":["tp1 = 0\n","tn1 = 0\n","fp1 = 0\n","fn1 = 0\n","for yt, yp in zip(y_test, y_pred):\n","    if yt == 1 and yp == 1:\n","        tp1 += 1\n","    elif yt == 0 and yp == 0:\n","        tn1 += 1\n","    else:\n","        if yp == 1:\n","            fp1 += 1\n","        else:\n","            fn1 += 1\n","\n","print(\"TP:\", tp1)\n","print(\"TN:\", tn1)\n","print(\"FP:\", fp1)\n","print(\"FN:\", fn1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"itTFOPyQaqWw","executionInfo":{"status":"ok","timestamp":1718394926479,"user_tz":300,"elapsed":194,"user":{"displayName":"Carlos Arturo Diaz Bonilla","userId":"01801615585783068100"}},"outputId":"93cf5eda-f3d6-4454-afd7-2004e38ef4f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TP: 28\n","TN: 33\n","FP: 1\n","FN: 298\n"]}]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelBinarizer\n","\n","# Binarize the labels\n","lb = LabelBinarizer()\n","y_true_binarized = lb.fit_transform(y_true)\n","y_score_binarized = lb.transform(y_score)\n","\n","# Calculate the ROC curve\n","fpr, tpr, thresholds = roc_curve(y_true_binarized, y_score_binarized[:, 1])\n","\n","# Calculate the AUC\n","roc_auc = auc(fpr, tpr)\n","\n","# Calculate FPR and TPR at a specific threshold\n","fpr_at_threshold = fpr[np.argmax(tpr > 0.5)]\n","tpr_at_threshold = tpr[np.argmax(tpr > 0.5)]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"3qrn28DGVAD0","executionInfo":{"status":"error","timestamp":1718395093279,"user_tz":300,"elapsed":211,"user":{"displayName":"Carlos Arturo Diaz Bonilla","userId":"01801615585783068100"}},"outputId":"6e444f81-36be-4de3-b4da-8db61a4ccd04"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"continuous target data is not supported with label binarization","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-e75f86e2148b>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_true_binarized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my_score_binarized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Calculate the ROC curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The object was not fitted with multilabel input.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         return label_binarize(\n\u001b[0m\u001b[1;32m    363\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mlabel_binarize\u001b[0;34m(y, classes, neg_label, pos_label, sparse_output)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0;34m\"%s target data is not supported with label binarization\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         )\n","\u001b[0;31mValueError\u001b[0m: continuous target data is not supported with label binarization"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}